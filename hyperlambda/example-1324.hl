
// Write a Hyperlambda script to ask OpenAI a question with a specified type and return the answer to the caller.
.arguments
   prompt:string
   type:string
   references:bool
   chat:bool
   recaptcha_response:string
   session:string
   user_id:string

/*
 * Forward invocation to chat file, since there are no real differences
 * between the two endpoints, since we're checking model type in chat file
 * and acting accordingly.
 * 
 * However, we still need to keep this file for legacy reasons.
 */
add:x:+
   get-nodes:x:@.arguments/*
io.file.execute:/system/openai/chat.get.hl
return:x:-/*
