
// Write a Hyperlambda script to unzip a specified file in its current folder, with an option to create a new folder. - With Python equivalent
.arguments
   file:string
   create_folder:bool
.type:internal

// Ensures user is authorized to access endpoint.
auth.ticket.verify:root

// Checking if we need to create folder with name and path of zip file.
if:x:@.arguments/*/create_folder
   strings.length:x:@.arguments/*/file
   strings.substring:x:@.arguments/*/file
      .:int:0
      math.subtract:x:@strings.length
         .:int:4
   strings.concat
      get-value:x:@strings.substring
      .:/
   unwrap:x:+/*/*
   add:x:../*/io.file.unzip
      .
         folder:x:@strings.concat
   if
      not
         io.folder.exists:x:@strings.concat
      .lambda

         // Creating folder we're unzipping into.
         io.folder.create:x:@strings.concat
   else

      // Deleting folder and re-creating it to ensure it's empty.
      io.folder.delete:x:@strings.concat
      io.folder.create:x:@strings.concat

// Unzipping file.
io.file.unzip:x:@.arguments/*/file

// Returning success to caller.
return-nodes
   result:success


/*

# Python equivalent
from flask import Flask, request, jsonify
import openai

app = Flask(__name__)

@app.route('/openai-chat', methods=['POST'])
def openai_chat():
    # Get the arguments from the request
    prompt = request.json.get('prompt')
    model_type = request.json.get('type', 'gpt-3.5-turbo')
    stream = request.json.get('stream', False)

    # Validate the prompt
    if not prompt:
        return jsonify({"error": "Prompt is mandatory"}), 400

    # Call the OpenAI API
    response = openai.Completion.create(
        engine=model_type,
        prompt=prompt,
        max_tokens=150,
        stream=stream
    )

    # Return the response
    return jsonify(response)

# Example usage: Run the Flask app
if __name__ == '__main__':
    app.run(debug=True)

*/